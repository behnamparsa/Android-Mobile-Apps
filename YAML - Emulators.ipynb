{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "812a59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extracted 471 emulator-related steps.\n",
      "üìÑ Steps saved to: emulator_steps_summary.csv\n",
      "üìÇ File grouping saved to: file_grouping_summary.csv\n",
      "üßæ JSON matches saved to: matched_steps.jsonl\n",
      "üìâ Keyword stats saved to: keyword_frequency_by_detection_method.csv\n",
      "‚ö†Ô∏è YAML parse errors saved to: yaml_parse_errors.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# === CONFIG ===\n",
    "EMULATOR_KEYWORDS = [\n",
    "    \"emulator\", \"avdmanager\", \"adb\", \"instrumentation\", \"start emulator\",\n",
    "    \"create avd\", \"android-emulator\", \"run emulator\", \"wait-for-device\"\n",
    "]\n",
    "\n",
    "PROJECTS_DIR = r\"C:\\Users\\Admin\\OneDrive\\Education\\Master of Info - Thesis\\Config Files\"\n",
    "OUTPUT_DIR = r\"C:\\GitHub\\Android-Mobile-Apps\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === DATA STRUCTURES ===\n",
    "records = []\n",
    "file_groups = []\n",
    "jsonl_matches = []\n",
    "\n",
    "# === MAIN PARSER ===\n",
    "def extract_yaml_steps(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = yaml.safe_load(f)\n",
    "\n",
    "        if not content:\n",
    "            file_groups.append({'file': file_path, 'group': 'empty or invalid YAML'})\n",
    "            return\n",
    "\n",
    "        parsed_ok = False\n",
    "        jobs = content.get('jobs', None)\n",
    "\n",
    "        # === STANDARD FORMAT ===\n",
    "        if isinstance(jobs, dict):\n",
    "            for job_name, job_data in jobs.items():\n",
    "                if not isinstance(job_data, dict):\n",
    "                    file_groups.append({'file': file_path, 'group': 'invalid job structure'})\n",
    "                    return\n",
    "\n",
    "                steps = job_data.get('steps', [])\n",
    "                if not isinstance(steps, list):\n",
    "                    file_groups.append({'file': file_path, 'group': 'invalid steps structure'})\n",
    "                    return\n",
    "\n",
    "                for step in steps:\n",
    "                    if not isinstance(step, dict):\n",
    "                        continue\n",
    "                    step_json = json.dumps(step, indent=2)\n",
    "                    if any(keyword in step_json.lower() for keyword in EMULATOR_KEYWORDS):\n",
    "                        parsed_ok = True\n",
    "                        match = {\n",
    "                            'file': file_path,\n",
    "                            'job': job_name,\n",
    "                            'step_name': step.get('name', ''),\n",
    "                            'matched_keywords': [k for k in EMULATOR_KEYWORDS if k in step_json.lower()],\n",
    "                            'detection_method': 'standard',\n",
    "                            'full_step_json': step_json\n",
    "                        }\n",
    "                        records.append(match)\n",
    "                        jsonl_matches.append(match)\n",
    "\n",
    "        # === FALLBACK FORMAT: TOP-LEVEL STEPS ===\n",
    "        elif isinstance(content, dict):\n",
    "            steps = content.get('steps', [])\n",
    "            if isinstance(steps, list):\n",
    "                for step in steps:\n",
    "                    if not isinstance(step, dict):\n",
    "                        continue\n",
    "                    step_json = json.dumps(step, indent=2)\n",
    "                    if any(keyword in step_json.lower() for keyword in EMULATOR_KEYWORDS):\n",
    "                        parsed_ok = True\n",
    "                        match = {\n",
    "                            'file': file_path,\n",
    "                            'job': 'top_level',\n",
    "                            'step_name': step.get('name', ''),\n",
    "                            'matched_keywords': [k for k in EMULATOR_KEYWORDS if k in step_json.lower()],\n",
    "                            'detection_method': 'top_level_fallback',\n",
    "                            'full_step_json': step_json\n",
    "                        }\n",
    "                        records.append(match)\n",
    "                        jsonl_matches.append(match)\n",
    "\n",
    "        # === DEEP FALLBACK: FULL FILE SCAN ===\n",
    "        if not parsed_ok:\n",
    "            flat_content = yaml.dump(content)\n",
    "            if any(keyword in flat_content.lower() for keyword in EMULATOR_KEYWORDS):\n",
    "                parsed_ok = True\n",
    "                match = {\n",
    "                    'file': file_path,\n",
    "                    'job': 'full_file_scan',\n",
    "                    'step_name': '',\n",
    "                    'matched_keywords': [k for k in EMULATOR_KEYWORDS if k in flat_content.lower()],\n",
    "                    'detection_method': 'full_file_scan',\n",
    "                    'full_step_json': 'Matched by full file scan'\n",
    "                }\n",
    "                records.append(match)\n",
    "                jsonl_matches.append(match)\n",
    "\n",
    "        # === CLASSIFY FILE ===\n",
    "        group_label = (\n",
    "            'parsed successfully' if parsed_ok else\n",
    "            'not parsed or empty'\n",
    "        )\n",
    "        file_groups.append({'file': file_path, 'group': group_label})\n",
    "\n",
    "    except yaml.YAMLError:\n",
    "        file_groups.append({'file': file_path, 'group': 'not parsed or empty'})\n",
    "    except Exception:\n",
    "        file_groups.append({'file': file_path, 'group': 'not parsed or empty'})\n",
    "\n",
    "# === DIRECTORY SCAN ===\n",
    "def scan_directory(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.yml', '.yaml')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                extract_yaml_steps(file_path)\n",
    "\n",
    "# === RUN ===\n",
    "scan_directory(PROJECTS_DIR)\n",
    "\n",
    "# === EXPORT MAIN CSV FILES ===\n",
    "pd.DataFrame(records).to_csv(os.path.join(OUTPUT_DIR, \"emulator_steps_summary.csv\"), index=False)\n",
    "pd.DataFrame(file_groups).to_csv(os.path.join(OUTPUT_DIR, \"file_grouping_summary.csv\"), index=False)\n",
    "\n",
    "# === EXPORT JSONL FILE ===\n",
    "jsonl_path = os.path.join(OUTPUT_DIR, \"matched_steps.jsonl\")\n",
    "with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "    for item in jsonl_matches:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# === Save files with YAML errors ===\n",
    "error_files = [f['file'] for f in file_groups if f['group'] == 'not parsed or empty']\n",
    "pd.DataFrame({'error_file': error_files}).to_csv(os.path.join(OUTPUT_DIR, \"yaml_parse_errors.csv\"), index=False)\n",
    "\n",
    "# === KEYWORD FREQUENCY BREAKDOWN BY DETECTION METHOD ===\n",
    "df_records = pd.DataFrame(records)\n",
    "keyword_stats = []\n",
    "\n",
    "for method in df_records['detection_method'].unique():\n",
    "    rows = df_records[df_records['detection_method'] == method]\n",
    "    keyword_list = list(chain.from_iterable(rows['matched_keywords']))\n",
    "    counter = Counter(keyword_list)\n",
    "    for keyword, count in counter.items():\n",
    "        keyword_stats.append({\n",
    "            'detection_method': method,\n",
    "            'keyword': keyword,\n",
    "            'count': count\n",
    "        })\n",
    "\n",
    "df_keyword_stats = pd.DataFrame(keyword_stats).sort_values(by=['detection_method', 'count'], ascending=[True, False])\n",
    "df_keyword_stats.to_csv(os.path.join(OUTPUT_DIR, \"keyword_frequency_by_detection_method.csv\"), index=False)\n",
    "\n",
    "# === LOG SUMMARY ===\n",
    "print(f\"\\n‚úÖ Extracted {len(records)} emulator-related steps.\")\n",
    "print(\"üìÑ Steps saved to: emulator_steps_summary.csv\")\n",
    "print(\"üìÇ File grouping saved to: file_grouping_summary.csv\")\n",
    "print(\"üßæ JSON matches saved to: matched_steps.jsonl\")\n",
    "print(\"üìâ Keyword stats saved to: keyword_frequency_by_detection_method.csv\")\n",
    "print(\"‚ö†Ô∏è YAML parse errors saved to: yaml_parse_errors.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
